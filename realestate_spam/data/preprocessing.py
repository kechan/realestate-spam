from typing import Any, List, Dict, Tuple, Union

import re
import pandas as pd

from abc import ABC, abstractmethod

from ..utils.misc import html_unescape

def coalesce_contact_cols(row):
  """
  Used to construct a new column CONTACT_STRUCT_INFO thats a combination of many names related columns.
  """
  given_name = row.GIVEN_NAME
  initial_name = row.INITIAL_NAME
  middle_name = row.MIDDLE_NAME
  family_name = row.FAMILY_NAME
  display_name = row.DISPLAY_NAME

  return coalesce_contact_cols_with(given_name, initial_name, middle_name, family_name, display_name)


def coalesce_contact_cols_with(given_name, initial_name, middle_name, family_name, display_name):
    """
    Combines the input names into a new string format.
    """
    return f"GIVEN_NAME: {given_name}, INITIAL_NAME: {initial_name}, MIDDLE_NAME: {middle_name}, FAMILY_NAME: {family_name}, DISPLAY_NAME: {display_name}"


# TODO: refactor the following 2 functions
def keep_user_input_only(df: pd.DataFrame):
  """
  Remove frequently occuring things from messages that were generated by the system 
  and not really part of user input.

  Use case:
  1) language detection (only for user input)
  2) preprocessing for test message data augmentation 
  """
  # TODO: assume NOTE in columns for now, generalize later if needed.
  assert 'NOTE' in df.columns, 'NOTE column must be present in the dataframe'

  df.NOTE = df.NOTE.str.replace("Website Contact Request - ", '')
  df.NOTE = df.NOTE.str.replace("Website Information Request - ", '')
  df.NOTE = df.NOTE.str.replace("Website Home Valuation Request - ", '')
  df.NOTE = df.NOTE.str.replace("Website Dream Home Request - ", '')
  df.NOTE = df.NOTE.str.replace("Website Careers Request", '')
  df.NOTE = df.NOTE.str.replace("Website Join Team Request", '')
  df.NOTE = df.NOTE.str.replace("New Exclusive Buying", '')
  df.NOTE = df.NOTE.str.replace("New Exclusive Selling", '')
  df.NOTE = df.NOTE.str.replace("Website Listing Info Request - ", '')
  df.NOTE = df.NOTE.str.replace("Website Free Home Evaluation Request - ", '')

  # replace all "MLS® W4797668 - " with ""

  # MLS® W3704460
  mls_pattern = r"MLS&reg; \w*\d+\s*-?\s*"
  html_unescape_mls_pattern = r"MLS®\s*\w*\d+\s*-?\s*"

  df.NOTE = df.NOTE.str.replace(mls_pattern, '', regex=True)
  df.NOTE = df.NOTE.str.replace(html_unescape_mls_pattern, '', regex=True)

  # MLS #135428
  mls_pattern = r"MLS\s*#\s*\d+\s*-?\s*"
  df.NOTE = df.NOTE.str.replace(mls_pattern, '', regex=True)

  # regex replace all similar to 'MLS® 601680071Website Listing Info Request' with ''
  mls_pattern = r"MLS&reg; \w*\d+Website Listing Info Request - "
  html_unescape_mls_pattern = r"MLS®\s*\w*\d+Website Listing Info Request - "
  df.NOTE = df.NOTE.str.replace(mls_pattern, '', regex=True)
  df.NOTE = df.NOTE.str.replace(html_unescape_mls_pattern, '', regex=True)

  # replace all "Single Property Website : New MLS® 201704850" with ""
  mls_pattern = r"Single Property Website\s*:\s*New MLS® \w*\d+"
  df.NOTE = df.NOTE.str.replace(mls_pattern, '', regex=True, flags=re.UNICODE)

  # replace all "Single Property Website : " with "" with optional ':'
  mls_pattern = r"Single Property Website\s*:?\s*"
  df.NOTE = df.NOTE.str.replace(mls_pattern, '', regex=True, flags=re.UNICODE)

  # replace all "New Listing ID: 30564529 " with ""
  mls_pattern = r"New Listing ID:\s*\w*\d+\s*"
  df.NOTE = df.NOTE.str.replace(mls_pattern, '', regex=True, flags=re.UNICODE)

  # replace all "Listing ID: 6321011" with ""
  mls_pattern = r"Listing ID:\s*\w*\d+\s*"
  df.NOTE = df.NOTE.str.replace(mls_pattern, '', regex=True, flags=re.UNICODE)

  # replace all "\n" and "\r" with " "
  df.NOTE = df.NOTE.str.replace("\n", ' ')
  df.NOTE = df.NOTE.str.replace("\r", ' ')

  # remove phrases like buying/selling house follow by a price range
  house_price_range_pattern = re.compile(r"(?i)(buying|selling|both)\s+house\s+([$\d,]+)\s+-\s+([$\d,]+)", re.IGNORECASE)
  df.NOTE = df.NOTE.str.replace(house_price_range_pattern, '', regex=True)

  # replace first few words related 'House ' with '', this seems to be system generated.
  df.NOTE = df.NOTE.str.replace("^\s*House\s*", '', regex=True, flags=re.UNICODE)
  df.NOTE = df.NOTE.str.replace("^\s*Buying House\s*", '', regex=True, flags=re.UNICODE)
  df.NOTE = df.NOTE.str.replace("^\s*Selling House\s*", '', regex=True, flags=re.UNICODE)
  df.NOTE = df.NOTE.str.replace("^\s*Both House\s*", '', regex=True, flags=re.UNICODE)

  # replace all hostnames with "[URL]"
  url_pattern = r"\b(?:https?://)?(?:www\.)?([a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}\b"
  df.NOTE = df.NOTE.str.replace(url_pattern, "", regex=True)

  # Trim of leading and trailing spaces
  df.NOTE = df.NOTE.str.strip()

  # Remove remaining about "New Exclusive" non user input
  exclusive_pattern = r"New Exclusive\s*Exclusive\s*"
  df.NOTE = df.NOTE.str.replace(exclusive_pattern, '', regex=True, flags=re.UNICODE)

  exclusive_pattern = r"^New Exclusive\s*"
  df.NOTE = df.NOTE.str.replace(exclusive_pattern, '', regex=True, flags=re.UNICODE)

def keep_user_input_str_only(note: str) -> str:
    """
    Remove frequently occuring things from a message that were generated by the system 
    and not really part of user input.

    Use case:
    1) language detection (only for user input)
    2) preprocessing for test message data augmentation 
    """

    note = note.replace("Website Contact Request - ", '')
    note = note.replace("Website Information Request - ", '')
    note = note.replace("Website Home Valuation Request - ", '')
    note = note.replace("Website Dream Home Request - ", '')
    note = note.replace("Website Careers Request", '')
    note = note.replace("Website Join Team Request", '')
    note = note.replace("New Exclusive Buying", '')
    note = note.replace("New Exclusive Selling", '')
    note = note.replace("Website Listing Info Request - ", '')
    note = note.replace("Website Free Home Evaluation Request - ", '')

    # replace all "MLS® W4797668 - " with ""
    mls_pattern = r"MLS&reg; \w*\d+\s*-?\s*"
    html_unescape_mls_pattern = r"MLS®\s*\w*\d+\s*-?\s*"
    note = re.sub(mls_pattern, '', note)
    note = re.sub(html_unescape_mls_pattern, '', note)

    # MLS #135428
    mls_pattern = r"MLS\s*#\s*\d+\s*-?\s*"
    note = re.sub(mls_pattern, '', note)

    # regex replace all similar to 'MLS® 601680071Website Listing Info Request' with ''
    mls_pattern = r"MLS&reg; \w*\d+Website Listing Info Request - "
    html_unescape_mls_pattern = r"MLS®\s*\w*\d+Website Listing Info Request - "
    note = re.sub(mls_pattern, '', note)
    note = re.sub(html_unescape_mls_pattern, '', note)

    # replace all "Single Property Website : New MLS® 201704850" with ""
    mls_pattern = r"Single Property Website\s*:\s*New MLS® \w*\d+"
    note = re.sub(mls_pattern, '', note, flags=re.UNICODE)

    # replace all "Single Property Website : " with "" with optional ':'
    mls_pattern = r"Single Property Website\s*:?\s*"
    note = re.sub(mls_pattern, '', note, flags=re.UNICODE)

    # replace all "New Listing ID: 30564529 " with ""
    mls_pattern = r"New Listing ID:\s*\w*\d+\s*"
    note = re.sub(mls_pattern, '', note, flags=re.UNICODE)

    # replace all "Listing ID: 6321011" with ""
    mls_pattern = r"Listing ID:\s*\w*\d+\s*"
    note = re.sub(mls_pattern, '', note, flags=re.UNICODE)

    # replace all "\n" and "\r" with " "
    note = note.replace("\n", ' ')
    note = note.replace("\r", ' ')

    # remove phrases like buying/selling house follow by a price range
    house_price_range_pattern = re.compile(r"(?i)(buying|selling|both)\s+house\s+([$\d,]+)\s+-\s+([$\d,]+)", re.IGNORECASE)
    note = re.sub(house_price_range_pattern, '', note)

    # replace first few words related 'House ' with '', this seems to be system generated.
    note = re.sub("^\s*House\s*", '', note, flags=re.UNICODE)
    note = re.sub("^\s*Buying House\s*", '', note, flags=re.UNICODE)
    note = re.sub("^\s*Selling House\s*", '', note, flags=re.UNICODE)
    note = re.sub("^\s*Both House\s*", '', note, flags=re.UNICODE)

    # replace all hostnames with "[URL]"
    url_pattern = r"\b(?:https?://)?(?:www\.)?([a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}\b"
    note = re.sub(url_pattern, "", note)

    # Trim leading and trailing spaces
    note = note.strip()

    # Remove remaining about "New Exclusive" non user input
    exclusive_pattern = r"New Exclusive\s*Exclusive\s*"
    note = re.sub(exclusive_pattern, '', note, flags=re.UNICODE)

    exclusive_pattern = r"^New Exclusive\s*"
    note = re.sub(exclusive_pattern, '', note, flags=re.UNICODE)

    return note

class BalancedSampler:
  def __init__(self, df, groupname, N, random_state=None):
    self.df = df
    self.groupname = groupname
    self.samples_per_category = N // len(df[groupname].unique())
    self.random_state = random_state
    self.balanced_df = self.create_balanced_df().sample(frac=1, random_state=self.random_state).reset_index(drop=True)

  def sample_func(self, group):
    unique_entries = group.drop_duplicates()
    if len(unique_entries) >= self.samples_per_category:
      return unique_entries.sample(self.samples_per_category, replace=False, random_state=self.random_state)
    else:
      additional_samples_needed = self.samples_per_category - len(unique_entries)
      additional_samples = group.sample(additional_samples_needed, replace=True, random_state=self.random_state)
      return pd.concat([unique_entries, additional_samples])

  def create_balanced_df(self):
    return self.df.groupby(self.groupname, group_keys=False).apply(self.sample_func)

  def generate_samples(self, colname=None):
    if colname:
      for value in self.balanced_df[colname]:
        yield value
    else:
      for row in self.balanced_df.itertuples(index=False):
        yield row

class PreprocessingPipeline(ABC):
  def __init__(self, df):
    self.df = df.copy()
    self.orig_df = df    # do not modify the original df

    assert 'DISPLAY_NAME' in self.df.columns, 'DISPLAY_NAME column must be present in the dataframe'
    assert 'NOTE' in self.df.columns, 'NOTE column must be present in the dataframe'
    assert self.df is not None, 'df must be provided'
    assert isinstance(self.df, pd.DataFrame), 'df must be a pandas dataframe'

  @abstractmethod
  def run(self):
    pass

  def __call__(self):
    return self.run()
  
class DistilledDataPipeline(PreprocessingPipeline):
  '''
  A preprocessing pipeline for distilled form of data.
  '''
  def __init__(self, df):
    super().__init__(df)
    self.class_id_to_name = {0: 'NOT_SPAM', 1: 'SPAM', 2: 'TEST'}
    self.name_to_class_id = {v: k for k, v in self.class_id_to_name.items()}

  def run(self):
    self.df.DISPLAY_NAME.fillna('n/a', inplace=True)
    self.df.NOTE.fillna('n/a', inplace=True)

    html_unescape(self.df)
    self.generate_text()
    self.add_label()

    self.sanity_check()

    return self.df


  def generate_text(self, note: str = None, display_name: str = None) -> Union[None, str]:    # the X in training
    '''
    text should be DISPLAY_NAME is <display_name>; <note>
    '''
    if note is not None and display_name is not None:
      return self._generate_text(note, display_name)     # working at str -> str level
    
    self.df['text'] = 'DISPLAY_NAME is ' + self.df.DISPLAY_NAME + '; ' + self.df.NOTE
 
  def add_label(self):
    '''
    this is an id, and we will use name_to_class_id
    '''
    self.df['label'] = self.df.class_label.apply(lambda x: self.name_to_class_id[x])
    
  def sanity_check(self):
    assert self.df.text.isnull().sum() == 0, 'text column cannot have null values'
    assert self.df.label.isnull().sum() == 0, 'label column cannot have null values'

    assert self.df.shape[0] == self.orig_df.shape[0], 'df should not have dropped any rows'

  def _generate_text(self, note: str, display_name: str) -> str:
    return 'DISPLAY_NAME is ' + display_name + '; ' + note
